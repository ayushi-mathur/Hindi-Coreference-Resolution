{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('./scripts/ssfapi/')\n",
    "import ssfAPI_intra as ssf\n",
    "\n",
    "reflexivePronouns = ['अपनी', 'अपने', 'अपना', 'स्वयं', 'खुद', 'खुद']\n",
    "relativePronouns = ['जो', 'जोकि', 'जहाँ', 'जिधर', 'जितना', 'जितने', 'जैसा', 'जैसे', 'जिसको', 'जिसके',\n",
    "    'जिस', 'जिसे', 'जिससे', 'जिसकी', 'जिसका', 'जिसने', 'जिन्हें', 'जिन्होंने', 'जिसमें', 'जिनमें', 'जिनकी']#removing \"jab\"\n",
    "firstPronouns = ['हमसे', 'हमारे', 'मेरा', 'मेरी', 'मेरे', 'हम', 'हमारा',\n",
    "                 'हमने', 'मुझे', 'मैं', 'मुझ', 'मैने', 'हमें', 'मैंने', 'हमारी']\n",
    "secondPronouns = ['आप', 'आपस', 'आपकी', 'आपके', 'आपको', 'आपका']\n",
    "locativePronouns = ['वहाँ', 'वहां', 'वहीं', 'यहीं', 'यहाँ', 'यहां',\n",
    "                    'जहां', 'जहाँ', 'कहीं', 'इसमें', 'उसमें', 'इनमें', 'जिसमें']\n",
    "\n",
    "linearChunkList = []\n",
    "linearnodelist=[]\n",
    "featureslist = [] #Numberr, Distance feature, NE?, Animacy\n",
    "trainingfeatures=[] #Number of pronoun, Number of NP, Distance b/w NP and pronoun chunk, Dist b/w NP and pronoun sent\n",
    "trainingresult=[]\n",
    "\n",
    "fileList = ssf.folderWalk('./data/')\n",
    "\n",
    "sent_number=0\n",
    "chunk_number=0\n",
    "\n",
    "for rfp in fileList:\n",
    "    relfile = False\n",
    "    doc = ssf.Document(rfp)\n",
    "    linearNodeList = []\n",
    "    for i, sentence in enumerate(doc.nodeList):\n",
    "        sent_number+=1\n",
    "        relsent = False\n",
    "        for chunk in sentence.nodeList:\n",
    "            flag=False\n",
    "            chunk_number+=1\n",
    "            for node in chunk.nodeList:\n",
    "                isPronoun = False\n",
    "                if node.name in firstPronouns:\n",
    "                    mention = node\n",
    "                    isPronoun = True\n",
    "                if node.name in secondPronouns:\n",
    "                    mention = node\n",
    "                    isPronoun = True\n",
    "                if node.name in reflexivePronouns:\n",
    "                    mention = node\n",
    "                    isPronoun = True\n",
    "                if (node.name in relativePronouns) and (node.morphPOS == 'pn'):\n",
    "                    mention = node\n",
    "                    isPronoun = True\n",
    "                if node.name in locativePronouns:\n",
    "                    mention = node\n",
    "                    isPronoun = True\n",
    "                if isPronoun:\n",
    "                    relfile = True\n",
    "                    relsent = True\n",
    "                    \n",
    "                    mentionLinksTo = 0 if mention.getAttribute('crefType') is None else mention.getAttribute('crefType').split(':')[1]\n",
    "                    chainsWithReferent = set()\n",
    "                    chainsWithMention = set()\n",
    "                    \n",
    "\n",
    "                    if (mention.getAttribute('cref') is not None):\n",
    "                        for c in mention.getAttribute('cref').split(','):\n",
    "                            chainsWithMention.add(c.split(':')[1])\n",
    "                    \n",
    "#                     for corefChain in doc.coreferenceChainNodeList:\n",
    "#                         for corefEntity in corefChain.nodeList:\n",
    "#                             if corefEntity.uniqueid == mentionLinksTo:\n",
    "#                                 chainsWithReferent.add(corefChain.chainid)\n",
    "\n",
    "                    for nons in range(len(linearChunkList)):\n",
    "                        curr_chunk=linearChunkList[nons]\n",
    "                        for nugger in curr_chunk.nodeList:\n",
    "                            chainsWithPrediction = set()\n",
    "                            answer=nugger\n",
    "                            if (answer.getAttribute('cref') is not None):\n",
    "                    \n",
    "                                for c in answer.getAttribute('cref').split(','):\n",
    "                                    if c == \"\" or c is None:\n",
    "                                        continue\n",
    "                                    chainsWithPrediction.add(c.split(':')[1])\n",
    "                            if len(set.intersection(chainsWithPrediction, chainsWithReferent, chainsWithMention)) > 0:\n",
    "                                flag=1\n",
    "                                print(\"YAAAAAAy\")\n",
    "                            else:\n",
    "                                flag=0\n",
    "                            \n",
    "                        trainingresult.append(flag)\n",
    "                        \n",
    "#                         for corefChain in doc.coreferenceChainNodeList:\n",
    "#                             for corefEntity in corefChain.nodeList:\n",
    "#                                 if answer in corefEntity.nodes:\n",
    "#                                     aChains.append(corefChain)\n",
    "#                         for a in aChains:\n",
    "#                             if a in mChains:\n",
    "#                                 flag = 1\n",
    "#                         if flag == 1:\n",
    "#                             trainingresult.append(1)\n",
    "#                         else:\n",
    "#                             trainingresult.append(0)\n",
    "                        trainingfeatures.append([node.number, featureslist[nons][0], chunk_number-featureslist[nons][2], sent_number-featureslist[nons][1]])\n",
    "                    \n",
    "                if node.type=='NN' or node.type=='NNP':\n",
    "                    flag=True\n",
    "                    linearChunkList.append(chunk)\n",
    "                    linearnodelist.append(node)\n",
    "                    featureslist.append([node.number, sent_number, chunk_number])\n",
    "                    break\n",
    "\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainingresult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
